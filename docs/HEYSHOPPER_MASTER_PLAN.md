# HeyShopper Master Plan: Complete Strategy & Architecture

**Date:** October 9, 2025  
**Status:** Ready for Implementation  
**Owner:** Allan Peretz, TestPilot CPG

---

## Executive Summary

Transform TestPilot ($20K revenue, 40 beta customers, $88K closing) into **two products**:

1. **TestPilot** - Standalone professional shopper testing platform
2. **HeyShopper** - TestPilot + full Robbieverse integration (conversational, intelligent, learning)

**Core differentiator:** Real shoppers (not BASES synthetic AI) + conversational interface + brand memory

**Timeline:** 6 months to $500K run rate  
**Investment:** Development costs offset by activity upsells and beta conversions

---

## The Two Products

### **TestPilot (app.testpilotcpg.com)**

**Positioning:** Professional shopper testing for CPG brands  
**Experience:** Clean, focused, traditional SaaS  
**Target:** Mid-market CPG brands ($5K-$15K budgets)

**Features:**
- 5 test modules (pricing, packaging, claims, head-to-head, advertising)
- Real shopper feedback
- AI-generated insights
- Statistical analysis
- PDF reports
- Multi-retailer (Amazon + Walmart)

**What's hidden:**
- Robbie personality (professional tone only)
- Cross-product intelligence
- Robbieverse ecosystem

**Pricing:** $1,225-$1,470 per test base + activity upsells

---

### **HeyShopper (heyshopper.com or within Robbieverse)**

**Positioning:** AI-powered testing that learns your brand  
**Experience:** Conversational, feels standalone but Robbieverse-powered  
**Target:** Advanced users, Robbieverse customers, high-volume testers

**Features:**
- **Everything TestPilot has**
- **+ RobbieChat interface** (conversational test setup, survey, analysis)
- **+ Vector intelligence** (learns from all past tests)
- **+ Personality system** (moods adapt to user)
- **+ Cross-product memory** (insights from Robbie@Work, etc.)
- **+ Proactive automation** (daily briefs, recommendations)
- **+ Statistical rigor** (custom sample size calculations)
- **+ Expert mode** (show/hide complexity)

**The difference:** Same platform, but connected to Robbieverse infrastructure

**Pricing:** Same base + intelligence layer value-add

---

## Core Differentiator: Real vs Synthetic

### **Market Segmentation (April 2025)**

| Provider | Data Type | Speed | Price | Use Case |
|----------|-----------|-------|-------|----------|
| **BASES AI Screener** | Synthetic (AI predictions) | 10 min | $500-$2K | Concept screening |
| **TestPilot/HeyShopper** | Real shoppers | 72 hours | $5K-$15K | Launch validation |
| **BASES Traditional** | Real shoppers | 2-4 weeks | $15K-$50K | Enterprise innovation |

**The Positioning:**

> "BASES gives you AI guesses in 10 minutes.  
> HeyShopper gives you real shoppers + AI that learns YOUR brand in 72 hours.  
> When $2M is on the line, which gives you confidence?"

**Why this wins:**
- BASES synthetic can't generate real qualitative feedback
- We have 1,298 real shopper quotes explaining WHY
- Our AI learns from real human behavior, not predictions

---

## The Goldmine: What We Already Have

### **1. Product Feedback (1,298 Responses)**
- `likes_most` text (what shoppers loved)
- `improve_suggestions` text (what to fix)
- `choose_reason` text (why they picked Product A vs B)
- **Real quotes BASES can't generate**

### **2. Platform Feedback (1,000 Entries)**
- Rating 1-5 + comments
- Tester experience feedback
- Pain points to fix: *"I would love the experience to be better"*
- **Continuous improvement engine**

### **3. AI Insights Already Generated**
- 25 AI insights with comparisons, purchase drivers, competitive analysis
- 57 purchase driver analyses
- 451 competitive insights
- **Already doing what competitors charge extra for**

### **4. Rich Statistical Data**
- 1,000+ tester sessions tracked
- 34 tests completed (73.5% completion rate)
- Multiple variants per test
- **Foundation for statistical rigor**

---

## The 5 Test Modules

All configured via **RobbieChat** (no rigid forms):

### **1. Pricing Test**
- Upload 1 product, specify 2-5 prices
- Base: 25 credits ($1,225)
- Recommended sample: 150 shoppers (detect 10% differences)
- Output: Optimal price point, elasticity curve

### **2. Packaging Test**
- Upload 2-5 package designs
- Base: 25 credits ($1,225)
- Recommended sample: 75 shoppers (visual preferences stronger)
- Output: Winning design, element analysis

### **3. Claims Test**
- 1 product, 2-5 claim variations
- Base: 25 credits ($1,225)
- Recommended sample: 225 shoppers (claims are subtle)
- Output: Most effective claim, trust analysis

### **4. Head-to-Head Test**
- Your product vs 1-4 competitors
- Base: 30 credits ($1,470)
- Recommended sample: 150 shoppers
- Output: Competitive positioning, market share prediction

### **5. Advertising Effectiveness Test** ðŸ†•
- Upload ad creative (image/video)
- Test vs control group
- Base: 30 credits ($1,470)
- Recommended sample: 150 shoppers (75 test + 75 control)
- Output: Ad recall, purchase intent, brand lift, ROI prediction

---

## Activities (Upsells)

**Post-survey premium add-ons:**

| Activity | Credits | Price | Description |
|----------|---------|-------|-------------|
| **Circle & Cross** | +10 | +$490 | Mark what you like/dislike on packaging |
| **Heat Map** | +15 | +$735 | Where eyes go first |
| **Drag-to-Rank** | +8 | +$392 | Rank elements by importance |
| **Emotional Response** | +12 | +$588 | Feelings about brand |

**Offered naturally in RobbieChat:**
```
Robbie: "Want shoppers to mark what they like on your 
packaging? Add Circle & Cross for +$490. Most packaging 
tests include this!"
```

**Revenue impact:**
- 30% attach rate on activities = +$23K/month
- Annual impact: +$276K

---

## RobbieChat Architecture: Everything Conversational

### **1. Test Setup (Customers)**

**Instead of forms, chat with Robbie:**
```
Allan: "Pricing test for my hot sauce"
Robbie: "ASIN or upload?"
Allan: "B08XYZ123"
Robbie: "Cholula! What prices?"
Allan: "$3.99, $4.99, $5.99"
Robbie: "150 shoppers recommended. Add Circle & Cross?"
Allan: "Yes"
Robbie: "60 credits ($2,940). Launch?"
[DONE - No forms!]
```

### **2. Shopper Survey (Testers)**

**Instead of rigid survey, conversational interview:**
```
Robbie: "Which catches your eye?"
Shopper: "The gold one"
Robbie: "What about it?"
Shopper: "Looks premium"
Robbie: "Worth $2 more?"
Shopper: "Yeah, looks quality"
[Data collected naturally through conversation]
```

### **3. Results Analysis (Customers)**

**Chat to explore insights:**
```
Allan: "What won?"
Robbie: "$5.99 won (67%). Want to know why?"
Allan: "Yes"
Robbie: "42 shoppers: 'premium packaging', 38: 'gold = quality'"
Allan: "What should I do?"
Robbie: "Launch at $5.99. Based on Cholula + this test, your 
audience values design > price. Pattern confirmed."
```

---

## Expert Mode: Progressive Disclosure

### **Simple Mode (90% of Users):**
- Robbie makes smart recommendations
- Hides statistical calculations
- Just tells you what to do
- Fast, easy, professional

### **Expert Mode (10% of Power Users):**
- Shows statistical formulas
- Allows parameter customization
- Advanced targeting options
- Full control over everything

**Toggle in Settings:**
```typescript
<ToggleSwitch 
  label="Expert Mode"
  description="Show advanced statistical controls and configuration options"
  checked={expertMode}
  onChange={toggleExpertMode}
/>
```

**What it reveals:**
- Statistical calculation details
- Custom screening questions
- Demographic overrides
- Confidence/power adjustments
- Regional targeting
- All the knobs and dials

---

## Statistical Testing Framework

### **Automatic Sample Size Calculation:**

```python
# When customer sets up test via RobbieChat
def recommend_sample_size(module: str, num_variants: int):
    defaults = STATISTICAL_DEFAULTS[module]
    
    # Calculate minimum viable
    minimum = calculate_minimum(
        variants=num_variants,
        effect_size=defaults['effectSize'],
        alpha=0.05,
        power=0.80
    )
    
    # Calculate recommended (20% buffer)
    recommended = math.ceil(minimum * 1.2)
    
    # Calculate premium (50% buffer)
    premium = math.ceil(minimum * 1.5)
    
    return {
        'minimum': minimum,
        'recommended': recommended,
        'premium': premium,
        'reasoning': defaults['reasoning'],
        'cost_recommended': recommended * 49
    }
```

### **Results Significance Testing:**

```python
def analyze_statistical_significance(test_id: str):
    responses = get_test_responses(test_id)
    
    # Chi-square goodness of fit
    chi2, p_value = stats.chisquare(
        f_obs=observed_frequencies,
        f_exp=expected_frequencies
    )
    
    # Pairwise z-tests
    pairwise_comparisons = []
    for variant_a, variant_b in itertools.combinations(variants, 2):
        z, p = proportions_ztest(
            count=[variant_a.selections, variant_b.selections],
            nobs=[variant_a.total, variant_b.total]
        )
        pairwise_comparisons.append({
            'comparison': f'{variant_a.name} vs {variant_b.name}',
            'statistically_significant': p < 0.05,
            'p_value': p,
            'winner': variant_a if z > 0 else variant_b
        })
    
    return {
        'overall_significant': p_value < 0.05,
        'p_value': p_value,
        'confidence_level': 1 - p_value,
        'pairwise': pairwise_comparisons,
        'robbie_explanation': generate_plain_english_explanation(
            p_value, pairwise_comparisons
        )
    }
```

### **RobbieChat Explains Stats:**

```
Allan: "Are these results significant?"

Robbie: "YES! Here's the breakdown:

Overall test: p-value = 0.003 (highly significant)
Translation: Less than 0.3% chance this is random

Pairwise comparisons:
âœ… $5.99 vs $3.99: p = 0.001 (VERY significant)
âœ… $5.99 vs $4.99: p = 0.042 (significant)
âš ï¸ $4.99 vs $3.99: p = 0.127 (not significant)

What this means:
- $5.99 is a clear winner (67% preference)
- It beat both other prices with statistical confidence
- $4.99 and $3.99 performed similarly (not enough data 
  to say one is better)

Confidence level: 99.7% - You can bet $2M on this! ðŸ’ª"

[If expert mode:]

Allan: "Show me the calculations"

Robbie: "Chi-square test:
Ï‡Â² = 24.67, df = 2, p = 0.003

Observed:
- $3.99: 12 (24%)
- $4.99: 15 (30%)
- $5.99: 33 (67%)

Expected (under null):
- Each: 16.67 (33.3%)

Z-tests:
- $5.99 vs $3.99: z = 3.44, p = 0.001
- $5.99 vs $4.99: z = 2.03, p = 0.042
- $4.99 vs $3.99: z = 1.52, p = 0.127

The 67% preference for $5.99 is WAY beyond random chance."
```

---

## Implementation Roadmap

### **Phase 0: Close $88K + Ship Walmart (Oct 9-21)**

**Week 1 (Oct 9-15):**
1. âœ… Analyze tester feedback (find top 3 pain points)
2. âœ… Fix: Add Amazon reviews to products
3. âœ… Fix: Flexible test flow (1 product, multiple prices)
4. âœ… Security fixes (unblock enterprise)
5. âœ… Multi-retailer pricing UI

**Week 2 (Oct 16-21):**
6. âœ… Close Simply Good Foods ($12,740)
7. âœ… Walmart soft launch (Oct 21)
8. âœ… Convert 2-3 from pipeline ($30K+)

**Success:** $50K+ closed by Oct 31

---

### **Phase 0.5: Conversational Foundation (Weeks 3-4)**

**Build core RobbieChat infrastructure:**

9. âœ… **Conversation engine** (node-based flow system)
10. âœ… **Test module system** (5 modules with dynamic setup)
11. âœ… **Statistical testing service** (sample size recommendations)
12. âœ… **Expert mode toggle** (show/hide complexity)

**Success:** Test setup via chat working for pricing module

---

### **Phase 1: Conversational Surveys (Weeks 5-8)**

**Replace rigid surveys with RobbieChat:**

13. âœ… **Conversational survey engine** (replaces forms)
14. âœ… **Data extraction from natural language** (ratings, insights)
15. âœ… **Activities system** (Circle & Cross, heat maps, drag-to-rank)
16. âœ… **Advertising module** (5th test type)
17. âœ… **A/B test** Survey vs Chat (measure completion rates)

**Success:** 90%+ survey completion (vs 73.5% current)

---

### **Phase 2: Intelligence Layer (Weeks 9-12)**

**Add vector intelligence:**

18. âœ… **Vector-enable feedback** (embed all qualitative text)
19. âœ… **Cross-test learning** (Robbie finds patterns across tests)
20. âœ… **Predictive recommendations** (Robbie suggests based on past)
21. âœ… **AskRobbie widget** (contextual help on every page)
22. âœ… **Automated report QA** (remove Allan/Dr. Dave bottleneck)

**Success:** 50% beta â†’ paid conversion (20 â†’ 10 customers)

---

### **Phase 3: Scale & Enterprise (Months 4-6)**

**Remove scale blockers:**

23. âœ… **Team collaboration** (multi-user accounts)
24. âœ… **Enhanced screening** (custom demographics)
25. âœ… **White-label reports** (agency/enterprise branding)
26. âœ… **Security & compliance** (SOC 2, SSO)

**Success:** $30K+ enterprise deals closing, $500K run rate

---

## The Data Architecture

### **Three Feedback Goldmines:**

#### **1. Product Feedback â†’ Customer Lock-In**

**Data:**
- 206 survey responses
- 1,000+ comparison responses  
- 92 Walmart comparisons
- All with qualitative text (likes_most, improve_suggestions, choose_reason)

**How Robbie uses it:**
```sql
-- Find similar feedback from past tests
SELECT likes_most, improve_suggestions, product_id
FROM responses_surveys rs
JOIN tests t ON t.id = rs.test_id
WHERE t.company_id = $customerId
ORDER BY rs.likes_most_embedding <=> $queryEmbedding
LIMIT 20;
```

**Result:**
```
Robbie: "Based on your Cholula test, shoppers valued 
'bold packaging' over price. I see the same pattern 
here. Expect 60%+ to choose premium design."
```

**Lock-in:** More tests = smarter Robbie = irreplaceable

#### **2. Platform Feedback â†’ Continuous Improvement**

**Data:**
- 1,000 tester experience feedback entries
- Ratings + comments about TestPilot itself
- Critical insight found: *"I wouldn't purchase without reviews"*

**How to use it:**
```python
# Identify pain points
low_ratings = query("SELECT * FROM feedback WHERE rating <= 2")

# Fix top issues
top_issues = categorize_and_rank(low_ratings)

# Measure improvement
track_change = query("""
    SELECT 
        CASE WHEN created_at < '2025-10-21' 
             THEN 'Before Walmart' 
             ELSE 'After Walmart' END as period,
        AVG(rating) as avg_rating
    FROM feedback
    GROUP BY period
""")
```

**Result:** Platform improves continuously based on real tester feedback

#### **3. Conversation Data â†’ Intelligence Engine**

**Data (NEW - will be generated):**
- Test setup conversations (customer configuring tests)
- Survey conversations (shoppers chatting with Robbie)
- Results conversations (customers exploring insights)

**How Robbie learns:**
```sql
-- Store all conversations with embeddings
CREATE TABLE survey_conversations (
  id UUID PRIMARY KEY,
  test_id UUID,
  tester_id UUID,
  conversation_transcript JSONB,
  extracted_data JSONB,
  insights_discovered TEXT[],
  embedding VECTOR(1536)
);

-- Find similar conversations
SELECT conversation_transcript, insights_discovered
FROM survey_conversations
WHERE company_id = $customerId
ORDER BY embedding <=> $queryEmbedding
LIMIT 10;
```

**Result:** Robbie learns conversation patterns, improves questions, discovers insights

---

## Statistical Rigor Framework

### **Module-Specific Recommendations:**

```typescript
const STATISTICAL_DEFAULTS = {
  pricing: {
    effectSize: 0.10,             // Detect 10% differences
    recommendedShoppers: 150,     // 50 per variant (3-way)
    reasoning: "Price sensitivity requires fine-grained detection"
  },
  packaging: {
    effectSize: 0.15,             // Detect 15% (visual stronger)
    recommendedShoppers: 75,      // 25 per variant
    reasoning: "Visual preferences are stronger signals"
  },
  claims: {
    effectSize: 0.08,             // Detect 8% (claims subtle)
    recommendedShoppers: 225,     // 75 per variant
    reasoning: "Claims are nuanced, need more power"
  },
  head_to_head: {
    effectSize: 0.12,             // Detect 12%
    recommendedShoppers: 150,     // 50 per product
    reasoning: "Competitive comparisons need clear preferences"
  },
  advertising: {
    effectSize: 0.20,             // Detect 20% brand lift
    recommendedShoppers: 150,     // 75 test + 75 control
    requiresControl: true,
    reasoning: "Ad effectiveness vs baseline requires control group"
  }
};
```

### **RobbieChat Explains Sample Size:**

**Simple mode:**
```
Robbie: "For 3-way pricing, recommend 150 shoppers ($7,350)"
```

**Expert mode:**
```
Allan: "Why 150?"
Robbie: "Stats breakdown:

Need to detect 10% preference difference with 95% confidence.
Formula: n = 2(Z_Î±/2 + Z_Î²)Â² Ã— p(1-p) / dÂ²
Calculation: 41 per variant Ã— 3 = 123 minimum
Recommended: 150 (20% safety buffer)

Want to adjust?
- Lower sensitivity (15%) â†’ 75 shoppers, $3,675
- Higher sensitivity (5%) â†’ 600 shoppers, $29,400

Your call based on launch stakes!"
```

---

## Revenue Model with Activities

### **Current (TestPilot):**
- Average test: $5,000
- 34 tests = $170,000 lifetime
- Actual revenue: $20K

### **With Modules + Activities (HeyShopper):**

**Base modules:**
- 5 modules @ $1,225-$1,470 average
- Average: $1,350 per test

**Activity attach rates:**
- 30% add 1 activity (+$400 avg) = +$405 per test
- 10% add 2+ activities (+$800 avg) = +$80 per test
- **New average: $1,835 per test**

**Revenue impact:**
- Current 34 tests/year @ $1,225 = $41,650
- With activities: 34 tests @ $1,835 = $62,390
- **+$20,740 per year (+50% revenue)**

**At scale (100 tests/year):**
- Base: $135,000
- With activities: $183,500
- **+$48,500 annually from activities alone**

---

## Go-to-Market Strategy

### **TestPilot Positioning:**

**Tagline:** "Real Shoppers. Real Insights. Real Confidence."

**Sales pitch:**
```
BASES AI Screener gives you synthetic shoppers (AI predictions) 
in 10 minutes for $2,000.

TestPilot gives you 50 real shoppers in 72 hours for $5,000.

When your CMO's job is on the line with a $2M SKU launch, 
which gives you confidence to bet the company?

Real human behavior. Real qualitative feedback. Real insights 
you can trust.
```

**Proof points:**
- Simply Good Foods chose real shoppers
- 40 beta customers validated product-market fit
- 1,298 real shopper quotes (BASES can't generate these)

---

### **HeyShopper Positioning:**

**Tagline:** "The shopper testing platform that learns your brand"

**Sales pitch:**
```
Most testing platforms give you data.

HeyShopper gives you an AI copilot that:
- Chats with you to set up tests (no forms)
- Interviews shoppers conversationally (not rigid surveys)
- Learns YOUR brand with every test
- Predicts outcomes based on past tests
- Suggests next tests automatically

By Test 3, Robbie knows your products better than anyone.

That's not just testing - that's intelligence.
```

**Proof points:**
- Powered by Robbieverse (proven AI platform)
- Real shoppers + AI intelligence (best of both worlds)
- 1,000+ feedback entries creating continuous improvement
- Custom statistical rigor per test design

---

## Success Metrics

### **Phase 0 (Oct 9-21):**
- âœ… $50K+ closed revenue
- âœ… Walmart tested by 5 beta customers
- âœ… Security audit passed
- âœ… Top 3 UX issues fixed

### **Phase 1 (Weeks 3-8):**
- âœ… Survey completion: 73.5% â†’ 90%+
- âœ… AskRobbie engagement: 60%+
- âœ… Activity attach rate: 30%+

### **Phase 2 (Weeks 9-12):**
- âœ… Beta â†’ paid conversion: 50% (20 â†’ 10)
- âœ… Report review time: 4 hrs â†’ 30 min
- âœ… Support tickets: -50%

### **Phase 3 (Months 4-6):**
- âœ… $500K annual run rate
- âœ… Enterprise deals closing
- âœ… Average test value: $1,835

---

## The Complete Vision

### **TestPilot:**
Professional shopper testing platform. Clean, simple, effective.

### **HeyShopper:**
TestPilot + Robbieverse = Intelligence platform that learns your brand.

### **The Key:**
**Feels standalone (shopper doesn't know about Robbieverse).  
Powered by ecosystem (shares infrastructure, intelligence, memory).**

**Think Apple:**
- iPhone works standalone (TestPilot)
- iPhone in Apple ecosystem (HeyShopper - iCloud, Handoff, etc.)
- User doesn't see the infrastructure
- Just works better together

---

**This is the plan. Everything flows through RobbieChat. Statistical rigor. Modular revenue. Real vs Synthetic positioning.** ðŸš€

**Ready to close that $88K and start building.** ðŸ’°

