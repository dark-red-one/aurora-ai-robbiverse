

# üöÄ AURORA AI - COMPLETE REBOOT SURVIVAL GUIDE

**For Allan: How to get EVERYTHING working after a reboot**

---

## üéØ THE GOAL

After a reboot, you want:
1. ‚úÖ **Robbie bar in Cursor** - Fully loaded with MCP servers
2. ‚úÖ **GPU mesh operational** - All nodes monitored and healthy
3. ‚úÖ **Dual 4090s accessible** - Local + Iceland/RunPod GPUs
4. ‚úÖ **Everything auto-recovers** - Self-healing infrastructure

---

## ‚ö° QUICK START (One-Time Setup)

### Option A: Auto-Start on Boot (Recommended)

```bash
bash ~/aurora-ai-robbiverse/deployment/setup-auto-boot.sh
```

**Done!** After next login, everything starts automatically.

### Option B: Manual Start After Reboot

```bash
bash ~/aurora-ai-robbiverse/deployment/boot-everything.sh
```

Run this after every reboot to start all services.

---

## üìä WHAT GETS STARTED

When you run the boot script, it starts:

### 1. Ollama Service (Local GPU)
- **Port**: 11434
- **Models**: 8 (qwen2.5:7b, deepseek-coder:33b, etc.)
- **Performance**: 4-5s inference for 7B models

### 2. Iceland/RunPod GPU Tunnel
- **Port**: 8080 ‚Üí Iceland GPU
- **SSH Tunnel**: Auto-reconnects on failure
- **Models**: 4 coding models including deepseek-coder:33b

### 3. GPU Mesh Monitor
- **Status**: Continuous health monitoring (every 30s)
- **Auto-Recovery**: Restarts failed nodes automatically
- **Alerts**: Real-time status with graduated severity
- **Dashboard**: Live updates every 60s

### 4. MCP Servers for Cursor
Your Cursor is configured with these MCP servers:
- `ollama-qwen` - Direct Ollama chat
- `dual-rtx4090` - GPU mesh router
- `aurora-backend` - Business intelligence
- `personality-sync` - Robbie personality
- `business-intelligence` - Deal pipeline tracking
- `daily-brief` - Morning summaries
- `smart-routing` - AI request router

---

## üîç VERIFY EVERYTHING IS WORKING

After boot, check status:

```bash
bash ~/aurora-ai-robbiverse/services/gpu-mesh/check-mesh-status.sh
```

You should see:

```
üü¢ Local Ollama (11434): HEALTHY - 8 models
üü¢ Iceland/RunPod (8080): HEALTHY - 4 models
```

---

## üéÆ USING YOUR GPU MESH IN CURSOR

When you open Cursor, the MCP servers auto-connect. You'll see:

### In Cursor's Status Bar:
- üü¢ `ollama-qwen` - Ready
- üü¢ `dual-rtx4090` - Ready
- üü¢ Other MCP servers

### Chat with GPUs:
Just start chatting! Cursor will automatically:
1. Route requests to best available GPU
2. Use local (fast) for quick tasks
3. Use Iceland (33B model) for complex coding
4. Auto-failover if a node goes down

---

## üß™ TEST IT ALL

### Test Local GPU

```bash
curl http://localhost:11434/api/generate -d '{
  "model": "qwen2.5:7b",
  "prompt": "Say hello",
  "stream": false
}' | jq -r '.response'
```

### Test Iceland GPU

```bash
curl http://localhost:8080/api/generate -d '{
  "model": "deepseek-coder:33b-instruct",
  "prompt": "Write a Python function to add numbers",
  "stream": false
}' | jq -r '.response'
```

### Test GPU Mesh

```bash
# View live mesh status
tail -f /tmp/aurora-gpu-mesh/gpu-mesh.log
```

---

## üõ†Ô∏è TROUBLESHOOTING

### Problem: Nothing starts after reboot

**Solution:**
```bash
# Run boot script manually
bash ~/aurora-ai-robbiverse/deployment/boot-everything.sh

# Check what failed
tail -100 /tmp/aurora-boot.log
```

### Problem: Ollama not responding

**Solution:**
```bash
# Check if running
ps aux | grep "ollama serve"

# If not, start it
ollama serve &

# Wait for it
sleep 3
curl http://localhost:11434/api/tags
```

### Problem: Iceland GPU tunnel down

**Solution:**
```bash
# Check tunnel
ps aux | grep "ssh.*8080"

# If down, restart it
ssh -i ~/.ssh/id_ed25519 -p 13323 \
    -L 8080:127.0.0.1:11434 \
    -N root@209.170.80.132 &

# Test it
sleep 5
curl http://localhost:8080/api/tags
```

### Problem: GPU Mesh not monitoring

**Solution:**
```bash
cd ~/aurora-ai-robbiverse/services/gpu-mesh
bash restart-mesh.sh
```

### Problem: Cursor MCP servers not connecting

**Solution:**
1. **Check if backends are running:**
   ```bash
   bash ~/aurora-ai-robbiverse/deployment/boot-everything.sh
   ```

2. **Restart Cursor:**
   - Completely quit Cursor
   - Reopen it
   - MCP servers should auto-connect

3. **Check MCP config:**
   ```bash
   cat ~/.cursor/mcp.json
   ```

---

## üìÅ KEY FILES & LOCATIONS

### Scripts
- **Boot everything**: `~/aurora-ai-robbiverse/deployment/boot-everything.sh`
- **Setup auto-boot**: `~/aurora-ai-robbiverse/deployment/setup-auto-boot.sh`
- **Check status**: `~/aurora-ai-robbiverse/services/gpu-mesh/check-mesh-status.sh`
- **Restart mesh**: `~/aurora-ai-robbiverse/services/gpu-mesh/restart-mesh.sh`

### Logs
- **Boot log**: `/tmp/aurora-boot.log`
- **Ollama log**: `/tmp/ollama.log`
- **GPU Mesh log**: `/tmp/aurora-gpu-mesh/gpu-mesh.log`
- **SSH tunnel logs**: `/tmp/ssh-tunnel-*.log`

### Config
- **Cursor MCP**: `~/.cursor/mcp.json`
- **GPU config**: `~/.cursor/dual-rtx4090-integration.json`
- **Ollama config**: `~/.cursor/ollama-config.json`

---

## üéØ YOUR DUAL RTX 4090 SETUP

### Current Configuration

| GPU | Port | Endpoint | Status |
|-----|------|----------|--------|
| **Local Ollama** | 11434 | `http://localhost:11434` | ‚úÖ 8 models |
| **Iceland/RunPod** | 8080 | `http://localhost:8080` (tunneled) | ‚úÖ 4 models |

### Total Capacity
- **12 models** across 2 GPU nodes
- **Local**: Fast general chat (4-5s, 7B models)
- **Iceland**: Heavy coding (20s, 33B models)
- **Auto-failover**: If one fails, other takes over

---

## üö® EMERGENCY: Nothing Works After Reboot

**Nuclear option - start from scratch:**

```bash
# 1. Kill everything
pkill -f "ollama serve"
pkill -f "unified_gpu_mesh"
pkill -f "ssh.*8080"

# 2. Wait
sleep 5

# 3. Start everything
bash ~/aurora-ai-robbiverse/deployment/boot-everything.sh

# 4. Verify
bash ~/aurora-ai-robbiverse/services/gpu-mesh/check-mesh-status.sh

# 5. If still broken, check logs
tail -100 /tmp/aurora-boot.log
tail -100 /tmp/ollama.log
tail -100 /tmp/aurora-gpu-mesh/gpu-mesh.log
```

---

## ‚úÖ SUCCESS CHECKLIST

After reboot, you should have:

- [ ] Ollama responding on localhost:11434
- [ ] Iceland GPU responding on localhost:8080
- [ ] GPU mesh monitoring both nodes
- [ ] Cursor MCP servers connected (green indicators)
- [ ] Can chat in Cursor and get AI responses
- [ ] GPU mesh auto-recovering failures
- [ ] All logs showing healthy status

---

## üéâ DAILY WORKFLOW

### Morning:
1. Open terminal
2. Check status: `bash ~/aurora-ai-robbiverse/services/gpu-mesh/check-mesh-status.sh`
3. See üü¢ üü¢ everywhere
4. Open Cursor
5. Start coding with Robbie!

### During the Day:
- Everything runs in background
- GPU mesh monitors and auto-recovers
- No manual intervention needed
- Check logs if curious: `tail -f /tmp/aurora-gpu-mesh/gpu-mesh.log`

### End of Day:
- Leave everything running (uses minimal resources)
- Will be ready tomorrow
- Auto-recovers if anything fails overnight

---

## üí° PRO TIPS

### Speed Up Boot Time
The boot script runs in background automatically. It takes ~10-15 seconds to start everything.

### Check If Auto-Start Is Working
```bash
grep -A 5 "AURORA AI AUTO-START" ~/.bashrc
```

### Disable Auto-Start Temporarily
```bash
# Comment out the auto-start section in ~/.bashrc
nano ~/.bashrc
# Add # before the boot-everything.sh line
```

### Force Restart Everything
```bash
# Nuclear restart
pkill -f "ollama\|unified_gpu_mesh\|ssh.*8080"
sleep 5
bash ~/aurora-ai-robbiverse/deployment/boot-everything.sh
```

---

## üéì UNDERSTANDING YOUR SETUP

### What You Have Now

1. **GPU Mesh** = Monitoring + Auto-recovery for all GPUs
2. **Dual 4090s** = Local Ollama + Iceland/RunPod (tunneled)
3. **MCP Servers** = Cursor integration for AI chat
4. **Auto-Boot** = Everything starts on login

### What Happens Behind the Scenes

1. **On Login** ‚Üí `boot-everything.sh` runs
2. **Starts Ollama** ‚Üí Local GPU ready
3. **Opens SSH Tunnel** ‚Üí Iceland GPU accessible
4. **Starts Mesh Monitor** ‚Üí Watches all nodes
5. **Cursor Opens** ‚Üí MCP servers auto-connect
6. **You Chat** ‚Üí Requests route to best GPU
7. **Node Fails** ‚Üí Mesh auto-restarts it
8. **You Never Notice** ‚Üí It just works‚Ñ¢

---

## üöÄ BOTTOM LINE

**After one-time setup:**
```bash
bash ~/aurora-ai-robbiverse/deployment/setup-auto-boot.sh
```

**You get:**
- ‚úÖ Everything auto-starts on boot
- ‚úÖ GPU mesh monitors and auto-recovers
- ‚úÖ Cursor MCP servers ready
- ‚úÖ Dual 4090s fully utilized
- ‚úÖ No manual intervention needed

**After reboot:**
1. Login
2. Wait 10-15 seconds
3. Open Cursor
4. Start coding

**That's it. The system is bulletproof.**

---

**Built with üí™ by Robbie for Allan's GPU empire**

*"I feel like we've been trying to get this shit working for days."*  
*"Now it works. Forever. After every reboot. No more fighting with it."* üöÄ




