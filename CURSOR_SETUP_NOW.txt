â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¥ CURSOR GPU SETUP - COPY/PASTE INSTRUCTIONS ğŸ”¥
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âš¡ CURRENT STATUS:
âœ… Proxy running on http://localhost:11435
âœ… Config file updated at ~/.config/Cursor/User/settings.json
âœ… 6 models ready to use

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STEP 1: RESTART CURSOR (30 seconds)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Close Cursor COMPLETELY (all windows)
2. Wait 5 seconds
3. Reopen Cursor

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STEP 2: VERIFY MODELS ARE VISIBLE (30 seconds)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Option A - Via Chat:
1. Press Ctrl+L (or Cmd+L on Mac)
2. Look at BOTTOM of chat panel
3. You should see a dropdown that says "Model: [something]"
4. Click it - you should see your 6 models listed

Option B - Via Settings:
1. Click âš™ï¸ (Settings) in bottom-left
2. Click "Cursor Settings"
3. Click "Models" in left sidebar
4. Scroll down to "Local Models" section
5. You should see all 6 models listed

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
IF MODELS DON'T SHOW UP - MANUAL CONFIG
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

If Cursor's UI doesn't show the models, do this:

1. Open Settings (âš™ï¸ â†’ Cursor Settings)
2. Click "Models" in sidebar
3. Scroll to "Override OpenAI Base URL"
4. Check the box "â˜‘ï¸ Override OpenAI Base URL"
5. In the URL field, enter:
   http://localhost:11435

6. In the "API Key" field, enter anything (it's ignored):
   robbie-local

7. Click "Add Model" button and add these one by one:
   - deepseek-coder:33b-instruct
   - codellama:13b-instruct
   - qwen2.5-coder:7b
   - deepseek-r1:7b
   - robbie:latest
   - qwen2.5:7b

8. Click "Save"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STEP 3: TEST IT (30 seconds)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Open Cursor Chat: Ctrl+L (Cmd+L)
2. Select model from dropdown: "qwen2.5-coder:7b"
3. Type: "Explain Python list comprehensions in one sentence"
4. Hit Enter
5. Should respond in < 3 seconds

If it works â†’ YOU'RE DONE! ğŸ‰
If it's slow (>30 sec) â†’ See troubleshooting below

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TROUBLESHOOTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem: Models don't show in dropdown
Solution: Use manual config steps above

Problem: Getting error "Connection refused"
Solution: Check proxy is running:
  curl http://localhost:11435/api/tags
  If fails, run: bash start-cursor-proxy.sh

Problem: Response is super slow (>30 sec)
Solution: Cursor might be using cloud API instead
  1. Go to Settings â†’ Models
  2. Make sure "Prefer local models" is checked
  3. Uncheck all cloud models (GPT-4, Claude, etc)

Problem: "Model not found" error
Solution: Check spelling exactly matches:
  deepseek-coder:33b-instruct
  (not deepseek-coder-33b or deepseek:33b)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
VERIFICATION COMMANDS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Run these in terminal to verify everything:

# Check proxy is running
curl http://localhost:11435/api/tags

# Check models are available
curl -s http://localhost:11435/api/tags | grep -o '"name":"[^"]*"'

# Check config file
cat ~/.config/Cursor/User/settings.json | grep -A2 "baseUrl"

# View proxy logs
tail -20 /tmp/cursor-proxy.log

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
EXPECTED OUTPUT WHEN WORKING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

When you ask Cursor a question:
1. Response starts in < 5 seconds
2. You see streaming text (not waiting forever)
3. Terminal shows in /tmp/cursor-proxy.log:
   "ğŸ¯ Routing [model-name] -> http://localhost:8080"
4. Local GPU usage goes up (check with: nvidia-smi)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
NUCLEAR OPTION (if nothing works)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Close Cursor completely
2. Run: rm -rf ~/.config/Cursor/Cache
3. Run: rm -rf ~/.config/Cursor/CachedData
4. Restart Cursor
5. Go through manual config steps above
6. Test again

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ BOTTOM LINE:
The infrastructure is ready. Now you just need to point
Cursor's UI at http://localhost:11435 and select a model.

Should take < 5 minutes total. Let's GO! ğŸš€

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”







